{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48376448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42011385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b443d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1161f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6817e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tqdm\n",
    "# !conda install -c conda-forge imageio -y\n",
    "# !pip install yacs\n",
    "#!pip install einops\n",
    "# !pip install --upgrade --no-cache-dir gdown\n",
    "# !pip install smplx\n",
    "# !pip install trimesh\n",
    "# !pip install h5py\n",
    "# !pip install pyrender\n",
    "# !pip install shapely\n",
    "# !pip install chumpy\n",
    "# !pip install mapbox_earcut\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "# !pip install moviepy\n",
    "#pip install scipy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d125e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge shapely pyrender trimesh mapbox_earcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067a4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c menpo osmesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d101153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "import visualize.plot_3d_global as plot_3d\n",
    "from glob import glob\n",
    "def to_xyz(motion, mean ,std , j = 22):\n",
    "    motion_xyz = recover_from_ric(motion.cpu().float()*std+mean, j)\n",
    "    motion_xyz = motion_xyz.reshape(motion.shape[0],-1, j, 3)\n",
    "    return motion_xyz\n",
    "\n",
    "            \n",
    "def sample_render(motion_xyz , name , save_path):\n",
    "    print(f\"render start\")\n",
    "    \n",
    "    gt_pose_vis = plot_3d.draw_to_batch(motion_xyz.numpy(),None, [os.path.join(save_path,name + \".gif\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d2361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9c08428",
   "metadata": {},
   "source": [
    "## Extract Encodec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d95cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66222652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f0d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_model = EncodecModel.encodec_model_24khz()\n",
    "encodec_model.set_target_bandwidth(6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f6a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82f4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_encoding(music_path,encodec_model):\n",
    "    wav, sr = torchaudio.load(music_path)\n",
    "    wav = convert_audio(wav, sr, 6400, encodec_model.channels)\n",
    "    wav = wav.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        encoded_frames = encodec_model.encode(wav[:,:,:])\n",
    "    music_encoding = encodec_model.decode2emb(encoded_frames)[0].T\n",
    "    return music_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91619a36",
   "metadata": {},
   "source": [
    "## Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf06343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained vqvae model files will be stored in the './checkpoints/vqvae/mix' folder\n",
      "\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1VPqPMC-28_8zerSIDzIMC1nQPMJgu3e3\n",
      "From (redirected): https://drive.google.com/uc?id=1VPqPMC-28_8zerSIDzIMC1nQPMJgu3e3&confirm=t&uuid=bae8b4f2-8240-4bd9-bb60-01b83e4b8ddb\n",
      "To: /home/sohan/Sem1/8903/FinalMusicMotion/MAGMA/checkpoints/vqvae/mix/vqvae_motion_best_fid.pt\n",
      "100%|██████████████████████████████████████| 1.83G/1.83G [01:06<00:00, 27.5MB/s]\n",
      "\n",
      "The pretrained motionseq model files will be stored in the './checkpoints/motionseq/encodec/' folder\n",
      "\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1JDetnPPX1YFJ004edBduWdrlwe-ZH48f\n",
      "From (redirected): https://drive.google.com/uc?id=1JDetnPPX1YFJ004edBduWdrlwe-ZH48f&confirm=t&uuid=e1628370-b9a3-425b-8876-ca58d6491bc7\n",
      "To: /home/sohan/Sem1/8903/FinalMusicMotion/MAGMA/checkpoints/motionseq/encodec/motionseq_encodec_best_fid.pt\n",
      "100%|██████████████████████████████████████| 1.15G/1.15G [00:41<00:00, 27.6MB/s]\n",
      "\n",
      "Downloading done!\n"
     ]
    }
   ],
   "source": [
    "!bash prepare/download_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84732ab8",
   "metadata": {},
   "source": [
    "## VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8351ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"./checkpoints/vqvae/mix/vqvae_mix.yaml\")\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(\"./checkpoints/vqvae/mix/vqvae_mix.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ca51817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"./checkpoints/vqvae/mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8ccfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e043e4",
   "metadata": {},
   "source": [
    "## MotionSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef004b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abdd9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([210000.])\n"
     ]
    }
   ],
   "source": [
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(\"./checkpoints/motionseq/encodec/encodec.yaml\")\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(\"./checkpoints/motionseq/encodec/motionseq_encodec_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0830734",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist_mean = np.load(\"./mean_std/aist/Mean.npy\")\n",
    "aist_std = np.load(\"./mean_std/aist/Std.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf6583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d72867f2",
   "metadata": {},
   "source": [
    "## Generate motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77562516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_motion_one_shot(music_encoding_):\n",
    "\n",
    "    max_seq_len = music_encoding_.shape[0]\n",
    "    print(max_seq_len)\n",
    "    gen_motion_indices_ = torch.randint(0 , 1024 , (1,1))\n",
    "\n",
    "\n",
    "    gen_motion = trans_model.generate(start_tokens =gen_motion_indices_.to(device),\\\n",
    "                                            seq_len=max_seq_len , \\\n",
    "                                            context = torch.Tensor(music_encoding_)[None,...].to(device), \\\n",
    "                                            context_mask=torch.ones((1 ,music_encoding_.shape[0]) , dtype = torch.bool).to(device),\\\n",
    "                                             )\n",
    "\n",
    "    out_motion = torch.zeros((1 ,gen_motion.shape[-1] , 263))\n",
    "    for i in range(0 , max_seq_len, 200):\n",
    "        quant , out_motion_= vqvae_model.decode(gen_motion[:,i:i+200].to(device))\n",
    "        out_motion[:,i:i+200] = out_motion_\n",
    "        \n",
    "    return out_motion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611d3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_motion_parts(music_encoding):\n",
    "\n",
    "    seq_len = 300\n",
    "    max_seq_len = music_encoding.shape[0]\n",
    "    print(max_seq_len)\n",
    "    gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "\n",
    "    gen_motion = []\n",
    "    torch.zeros((1,max_seq_len) , dtype = torch.long)\n",
    "\n",
    "\n",
    "    for i in range(0,max_seq_len,seq_len):\n",
    "\n",
    "        music_encoding_ = music_encoding[max(i-1 , 0):max(i-1 , 0)+seq_len]\n",
    "        print(\"music_encoding_\", music_encoding_.shape)\n",
    "\n",
    "        gen_motion_indices_ = gen_motion_indices[:,-1:]\n",
    "\n",
    "        gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices_.to(device),\\\n",
    "                                                  temperature = 0.8,\n",
    "                                                seq_len=music_encoding_.shape[0] , \\\n",
    "                                                context = torch.Tensor(music_encoding_)[None,...].to(device), \\\n",
    "                                                context_mask=torch.ones((1 ,music_encoding_.shape[0]) , dtype = torch.bool).to(device),\\\n",
    "                                                 )\n",
    "\n",
    "        gen_motion.append(gen_motion_indices[0,1:])\n",
    "\n",
    "\n",
    "    gen_motion = torch.cat(gen_motion )[None, :max_seq_len]\n",
    "\n",
    "\n",
    "    out_motion = torch.zeros((1 ,gen_motion.shape[-1] , 263))\n",
    "    for i in range(0 , max_seq_len, 200):\n",
    "        quant , out_motion_= vqvae_model.decode(gen_motion[:,i:i+200].to(device))\n",
    "        out_motion[:,i:i+200] = out_motion_\n",
    "        \n",
    "    return out_motion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa2f413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcaccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"./music/whip.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d7a6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_encoding = get_music_encoding(src, encodec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ca81178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3286, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4528afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "music_encoding_ torch.Size([50, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:04<00:00, 10.26it/s]\n"
     ]
    }
   ],
   "source": [
    "generated_motion = generate_motion_parts(music_encoding[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009114e",
   "metadata": {},
   "source": [
    "## Render stick figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ad5fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "music_name= os.path.basename(src).split(\".\")[0]\n",
    "save_pth = \"./results/\"\n",
    "sample_render(to_xyz(generated_motion.detach().cpu(),mean = aist_mean , std = aist_std), name = music_name+\"_k\" , save_path = save_pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f8e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4098bf2e",
   "metadata": {},
   "source": [
    "## Render SMPL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d23226b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smpl files will be stored in the 'body_models/smpl/' folder\n",
      "\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1INYlGA76ak_cKGzvpOV2Pe6RkYTlXTW2\n",
      "From (redirected): https://drive.google.com/uc?id=1INYlGA76ak_cKGzvpOV2Pe6RkYTlXTW2&confirm=t&uuid=b68bf8aa-96ba-4a14-8740-30ffd1f5c7fc\n",
      "To: /home/sohan/Sem1/8903/FinalMusicMotion/MAGMA/body_models/smpl.zip\n",
      "100%|██████████████████████████████████████| 35.3M/35.3M [00:01<00:00, 32.4MB/s]\n",
      "Archive:  smpl.zip\n",
      "   creating: smpl/\n",
      "  inflating: smpl/J_regressor_extra.npy  \n",
      "  inflating: smpl/smplfaces.npy      \n",
      "  inflating: smpl/kintree_table.pkl  \n",
      "  inflating: smpl/SMPL_NEUTRAL.pkl   \n",
      "Cleaning\n",
      "\n",
      "Downloading done!\n"
     ]
    }
   ],
   "source": [
    "!bash ./prepare/download_smpl.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa4feae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the following packages to render SMPL\n",
    "\n",
    "# conda install -c menpo osmesa\n",
    "# conda install h5py\n",
    "# conda install -c conda-forge shapely pyrender trimesh mapbox_earcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb7783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from render_final import render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0ebac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "torch.Size([1, 6890, 3, 50])\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "row index exceeds matrix dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m save_pth \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m motion_xyz \u001b[38;5;241m=\u001b[39m to_xyz(generated_motion\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu() , mean\u001b[38;5;241m=\u001b[39m aist_mean , std \u001b[38;5;241m=\u001b[39m aist_std)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmotion_xyz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_pth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmusic_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_smpl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Sem1/8903/FinalMusicMotion/MAGMA/render_final.py:120\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(motions, outdir, step, name, pred, device)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m## OPAQUE rendering without alpha\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m## BLEND rendering consider alpha \u001b[39;00m\n\u001b[1;32m    113\u001b[0m material \u001b[38;5;241m=\u001b[39m pyrender\u001b[38;5;241m.\u001b[39mMetallicRoughnessMaterial(\n\u001b[1;32m    114\u001b[0m     metallicFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m    115\u001b[0m     alphaMode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPAQUE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    116\u001b[0m     baseColorFactor\u001b[38;5;241m=\u001b[39mbase_color\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 120\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mpyrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_trimesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaterial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaterial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m polygon_mesh\u001b[38;5;241m.\u001b[39mvisual\u001b[38;5;241m.\u001b[39mface_colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.21\u001b[39m]\n\u001b[1;32m    123\u001b[0m polygon_render \u001b[38;5;241m=\u001b[39m pyrender\u001b[38;5;241m.\u001b[39mMesh\u001b[38;5;241m.\u001b[39mfrom_trimesh(polygon_mesh, smooth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/MAGMA/lib/python3.8/site-packages/pyrender/mesh.py:202\u001b[0m, in \u001b[0;36mMesh.from_trimesh\u001b[0;34m(mesh, material, is_visible, poses, wireframe, smooth)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m smooth:\n\u001b[1;32m    201\u001b[0m     positions \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 202\u001b[0m     normals \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertex_normals\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    203\u001b[0m     indices \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mfaces\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trimesh/caching.py:139\u001b[0m, in \u001b[0;36mcache_decorator.<locals>.get_cached\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mcache[name]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# value not in cache so execute the function\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# store the value\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mforce_immutable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    142\u001b[0m         value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trimesh/base.py:447\u001b[0m, in \u001b[0;36mTrimesh.vertex_normals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mThe vertex normals of the mesh. If the normals were loaded\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03mwe check to make sure we have the same number of vertex\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m  Where n == len(self.vertices)\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# make sure we have faces_sparse\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfaces_sparse\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    448\u001b[0m vertex_normals \u001b[38;5;241m=\u001b[39m geometry\u001b[38;5;241m.\u001b[39mweighted_vertex_normals(\n\u001b[1;32m    449\u001b[0m     vertex_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices),\n\u001b[1;32m    450\u001b[0m     faces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaces,\n\u001b[1;32m    451\u001b[0m     face_normals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_normals,\n\u001b[1;32m    452\u001b[0m     face_angles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_angles)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vertex_normals\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trimesh/caching.py:139\u001b[0m, in \u001b[0;36mcache_decorator.<locals>.get_cached\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mcache[name]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# value not in cache so execute the function\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# store the value\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mforce_immutable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    142\u001b[0m         value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trimesh/base.py:300\u001b[0m, in \u001b[0;36mTrimesh.faces_sparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;129m@caching\u001b[39m\u001b[38;5;241m.\u001b[39mcache_decorator\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfaces_sparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    A sparse matrix representation of the faces.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m      shape : (len(self.vertices), len(self.faces))\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     sparse \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_sparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfaces\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trimesh/geometry.py:459\u001b[0m, in \u001b[0;36mindex_sparse\u001b[0;34m(columns, indices, data)\u001b[0m\n\u001b[1;32m    456\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(col), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# assemble into sparse matrix\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoo_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "File \u001b[0;32m~/miniconda3/envs/MAGMA/lib/python3.8/site-packages/scipy/sparse/_coo.py:197\u001b[0m, in \u001b[0;36mcoo_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MAGMA/lib/python3.8/site-packages/scipy/sparse/_coo.py:284\u001b[0m, in \u001b[0;36mcoo_matrix._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow index exceeds matrix dimensions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn index exceeds matrix dimensions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: row index exceeds matrix dimensions"
     ]
    }
   ],
   "source": [
    "music_name= os.path.basename(src).split(\".\")[0]\n",
    "\n",
    "save_pth = \"./results/\"\n",
    "motion_xyz = to_xyz(generated_motion.detach().cpu() , mean= aist_mean , std = aist_std)\n",
    "render(motion_xyz[0].numpy(), outdir= os.path.join(save_pth), name=music_name+ \"_smpl\", pred=True ,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42a7f388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/sohan/miniconda3/envs/MAGMA/lib/python3.8/site-packages (1.7.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/sohan/miniconda3/envs/MAGMA/lib/python3.8/site-packages (from scipy) (1.20.3)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.1\n",
      "    Uninstalling scipy-1.7.1:\n",
      "      Successfully uninstalled scipy-1.7.1\n",
      "Successfully installed scipy-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01590a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d57394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
